{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35673b66-5e44-4b21-a076-dd6c2e83ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from matplotlib import transforms\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from statsmodels.stats import multitest\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "# clustering libraries\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "\n",
    "import umap\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e8814-fb69-4a75-a956-065705efe523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_artist(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6a4b8-66e0-49b5-a884-f157b566e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6baed1-d876-4c9b-8ce9-d43f6d05826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gliph = pd.read_csv(\"parsed_gliph_file.tsv\", sep=\"\\t\")\n",
    "\n",
    "gliph_data_t = gliph.loc[:,\"A02_Yes:3M\":].transpose()\n",
    "\n",
    "#gliph_data_t_scaled = RobustScaler(with_centering=False).fit_transform(gliph_data_t)\n",
    "#gliph_data_t_scaled = StandardScaler().fit_transform(gliph_data_t)\n",
    "gliph_data_t_scaled = MaxAbsScaler().fit_transform(gliph_data_t)\n",
    "\n",
    "gliph_data_t_scaled_df = pd.DataFrame(gliph_data_t_scaled, columns = gliph_data_t.columns, index=gliph_data_t.index.values)\n",
    "\n",
    "\n",
    "gliph_embedding = reducer.fit_transform(gliph_data_t_scaled)\n",
    "gliph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7d5ca-768c-4743-910d-b063182539c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gliph_data = gliph.loc[:,\"A02_Yes:3M\":]\n",
    "\n",
    "#gliph_data_scaled = StandardScaler().fit_transform(gliph_data)\n",
    "#gliph_data_scaled = RobustScaler(with_centering=False).fit_transform(gliph_data)\n",
    "gliph_data_scaled = MaxAbsScaler().fit_transform(gliph_data)\n",
    "\n",
    "gliph_data_scaled.shape\n",
    "\n",
    "gliph_data_scaled_df = pd.DataFrame(gliph_data_scaled, columns = gliph_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7063140-c561-45a1-9936-42ce2eb332c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gliph_data_t_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871c122-19cf-4b56-83a2-c9d859987fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gliph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d70c7a-d176-4d30-b1e0-d5fd03cf0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "gliph_data_t.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_yesno = list()\n",
    "timepoints_all = list()\n",
    "responders = list()\n",
    "non_responders = list()\n",
    "timepoints_bl = list()\n",
    "timepoints_6w = list()\n",
    "timepoints_3m = list()\n",
    "\n",
    "for sample in gliph_data_t.index.values:\n",
    "    splitone = sample.split(\":\")\n",
    "    splittwo = splitone[0].split(\"_\")\n",
    "    timepoints_all.append(splitone[1])\n",
    "    response_yesno.append(splittwo[1])\n",
    "\n",
    "    if splitone[1] == \"BL\":\n",
    "        timepoints_bl.append(sample)\n",
    "    if splitone[1] == \"6W\":\n",
    "        timepoints_6w.append(sample)\n",
    "    if splitone[1] == \"3M\":\n",
    "        timepoints_3m.append(sample)\n",
    "    if splittwo[1] == \"Yes\":\n",
    "        responders.append(sample)\n",
    "    if splittwo[1] == \"No\":\n",
    "        non_responders.append(sample)\n",
    "\n",
    "print(response_yesno)\n",
    "print(timepoints_all)\n",
    "print(timepoints_bl)\n",
    "print(timepoints_6w)\n",
    "print(timepoints_3m)\n",
    "print(responders)\n",
    "print(non_responders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ea3cb-c4ac-4aa3-a3e1-353595e966e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = int(gliph_data_scaled.shape[0]/100)\n",
    "md = 0.25\n",
    "\n",
    "fit = umap.UMAP(\n",
    "    n_neighbors=nn,\n",
    "    min_dist=md,\n",
    "    n_components=2,\n",
    "    metric=\"euclidean\",\n",
    "    random_state=42        \n",
    ")\n",
    "gliph_embedding_clusters = fit.fit_transform(gliph_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6b5db-e584-43c6-a5ea-920875e68600",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    gliph_embedding_clusters[:, 0],\n",
    "    gliph_embedding_clusters[:, 1],\n",
    "    c=\"black\",\n",
    "    s=100,\n",
    "    alpha=0.03)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'UMAP of GLIPH2 convergence groups\\nn_neighbors={nn} min_dist={md}', fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7372c-ca6e-4af4-8aef-29f8b3019bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_labels = hdbscan.HDBSCAN(min_samples=None, min_cluster_size=100).fit_predict(gliph_embedding_clusters)\n",
    "clustered = (hdbscan_labels >= 0)\n",
    "plt.scatter(gliph_embedding_clusters[~clustered, 0],\n",
    "            gliph_embedding_clusters[~clustered, 1],\n",
    "            color=(0.5, 0.5, 0.5),\n",
    "            s=100,\n",
    "            alpha=0.5)\n",
    "plt.scatter(gliph_embedding_clusters[clustered, 0],\n",
    "            gliph_embedding_clusters[clustered, 1],\n",
    "            c=hdbscan_labels[clustered],\n",
    "            s=100,\n",
    "            cmap='Spectral',\n",
    "            alpha=0.5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(\"UMAP of GLIPH2 convergence groups with HDBSCAN clustering.\\nGrey nodes unclustered, clustered points in total: {}%\".format(\n",
    "    100*round(float(len(gliph_embedding_clusters[clustered]))/float(len(gliph_embedding_clusters)), 3)), fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bc31c-0599-4d68-b2d4-52527c06fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(hdbscan_labels))-1\n",
    "#Num clusters in hdbscan, -1 because of the unclustered points ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff947f-e1fb-4ab8-ae3c-d98f8b6e8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcox_results = pd.DataFrame({'statistic_count': [], 'pvalue_count': [], 'statistic_scaled': [], 'pvalue_scaled': []})\n",
    "\n",
    "for i in range(0,len(set(hdbscan_labels))-1):\n",
    "    tmp_count = gliph_data[hdbscan_labels==i]\n",
    "\n",
    "    tmp_count_yes = tmp_count[responders]\n",
    "\n",
    "    tmp_count_no = tmp_count[non_responders]\n",
    "\n",
    "    statistic_count, pvalue_count = scipy.stats.ranksums(np.concatenate(tmp_count_no.to_numpy()), np.concatenate(tmp_count_yes.to_numpy()))\n",
    "    #wilcox_results.loc[len(wilcox_results.index)] = [statistic, pvalue]\n",
    "    #print(statistic, pvalue)\n",
    "    \n",
    "    tmp_scaled = gliph_data_scaled_df[hdbscan_labels==i]\n",
    "\n",
    "    tmp_scaled_yes = tmp_scaled[responders]\n",
    "\n",
    "    tmp_scaled_no = tmp_scaled[non_responders]\n",
    "    \n",
    "    statistic_scaled, pvalue_scaled = scipy.stats.ranksums(np.concatenate(tmp_scaled_no.to_numpy()), np.concatenate(tmp_scaled_yes.to_numpy()))\n",
    "    wilcox_results.loc[len(wilcox_results.index)] = [statistic_count, pvalue_count, statistic_scaled, pvalue_scaled]\n",
    "wilcox_results.sort_values(by=\"statistic_scaled\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7512d82-3d4a-4839-bc2e-3495d5164899",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_corrected_pvalues = multitest.fdrcorrection(np.concatenate(wilcox_results[[\"pvalue_count\"]].values), alpha=0.01)\n",
    "hdbscan_cluster_indices_which_pass_test = np.asarray(wilcox_results[fdr_corrected_pvalues[0]].index)\n",
    "hdbscan_cluster_indices_which_pass_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ba64e-024d-4bbb-a1ef-97aae5eb402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_clustered = (hdbscan_labels >= 0)\n",
    "plt.scatter(gliph_embedding_clusters[:, 0],\n",
    "            gliph_embedding_clusters[:, 1],\n",
    "            color=(0.5, 0.5, 0.5),\n",
    "            s=100,\n",
    "            alpha=0.1)\n",
    "\n",
    "x_coords = list()\n",
    "y_coords = list()\n",
    "cols = list()\n",
    "\n",
    "for i in range(len(hdbscan_cluster_indices_which_pass_test)):\n",
    "    cluster_index_points = (hdbscan_labels == hdbscan_cluster_indices_which_pass_test[i])\n",
    "    #print([cluster_index]*list(cluster_index_points).count(True))\n",
    "    x_coords += list(gliph_embedding_clusters[cluster_index_points, 0])\n",
    "    y_coords += list(gliph_embedding_clusters[cluster_index_points, 1])\n",
    "    cols += [float(i)]*list(cluster_index_points).count(True)\n",
    "\n",
    "\n",
    "plt.scatter(x_coords,\n",
    "            y_coords,\n",
    "            s=100,\n",
    "            c=cols,\n",
    "            cmap='Spectral',\n",
    "            alpha=0.5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(\"UMAP of GLIPH2 convergence groups \\ncoloured if the cluster has a significantly different \\ndistribution of clone counts between responders and non-responders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6f475-8456-467a-a417-e4e306279395",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_individual_points_pure = list()\n",
    "cols_individual_points_greater = list()\n",
    "cols_individual_points_log2_1 = list()\n",
    "cols_individual_points_log2_2 = list()\n",
    "cols_individual_points_log2_3 = list()\n",
    "\n",
    "cols_timepoint_which_is_top = list()\n",
    "cols_timepoint_pure = list()\n",
    "cols_timepoint_log2_2 = list()\n",
    "\n",
    "for i in range(gliph.shape[0]):\n",
    "    yes_count = np.array(gliph_data_scaled_df[responders].loc[i]).sum() / len(responders)\n",
    "    no_count = np.array(gliph_data_scaled_df[non_responders].loc[i]).sum() / len(non_responders)\n",
    "\n",
    "    bl_count = np.array(gliph_data_scaled_df[timepoints_bl].loc[i]).sum() / len(timepoints_bl)\n",
    "    sixW_count = np.array(gliph_data_scaled_df[timepoints_6w].loc[i]).sum() / len(timepoints_6w)\n",
    "    threeM_count = np.array(gliph_data_scaled_df[timepoints_3m].loc[i]).sum() / len(timepoints_3m)\n",
    "    \n",
    "    no_col = '#EE667759'\n",
    "    mixed_col = '#4477AA59'\n",
    "    yes_col = '#22883359'\n",
    "\n",
    "    bl_col = '#EE667759'\n",
    "    sixW_col = '#4477AA59'\n",
    "    threeM_col = '#22883359'\n",
    "    \n",
    "    else_col = '#AAAAAA03'\n",
    "    \n",
    "\n",
    "    if hdbscan_labels[i] in hdbscan_cluster_indices_which_pass_test:\n",
    "    \n",
    "        # pure = all counts are from YES or NO, if any count in both it is MIXED\n",
    "        if yes_count == 0 and no_count != 0:\n",
    "            cols_individual_points_pure.append(no_col)\n",
    "        elif no_count == 0 and yes_count != 0:\n",
    "            cols_individual_points_pure.append(yes_col)\n",
    "        else:\n",
    "            cols_individual_points_pure.append(mixed_col) \n",
    "    \n",
    "        if yes_count < no_count:\n",
    "            cols_individual_points_greater.append(no_col)\n",
    "        elif yes_count > no_count:\n",
    "             cols_individual_points_greater.append(yes_col)\n",
    "        else:\n",
    "            cols_individual_points_greater.append(mixed_col)\n",
    "        \n",
    "        if yes_count < no_count and yes_count*2 < no_count:\n",
    "            cols_individual_points_log2_1.append(no_col)\n",
    "        elif yes_count > no_count and yes_count > no_count*2:\n",
    "            cols_individual_points_log2_1.append(yes_col)\n",
    "        else:\n",
    "            cols_individual_points_log2_1.append(mixed_col)\n",
    "             \n",
    "        if yes_count < no_count and yes_count*4 < no_count:\n",
    "            cols_individual_points_log2_2.append(no_col)\n",
    "        elif yes_count > no_count and yes_count > no_count*4:\n",
    "            cols_individual_points_log2_2.append(yes_col)\n",
    "        else:\n",
    "            cols_individual_points_log2_2.append(mixed_col)\n",
    "        \n",
    "        if yes_count < no_count and yes_count*8 < no_count:\n",
    "            cols_individual_points_log2_3.append(no_col)\n",
    "        elif yes_count > no_count and yes_count > no_count*8:\n",
    "            cols_individual_points_log2_3.append(yes_col)\n",
    "        else:\n",
    "            cols_individual_points_log2_3.append(mixed_col)\n",
    "\n",
    "\n",
    "        # timepoint_counts\n",
    "        if bl_count > threeM_count and bl_count > sixW_count:\n",
    "            cols_timepoint_which_is_top.append(bl_col)\n",
    "        elif threeM_count > bl_count and threeM_count > sixW_count:\n",
    "            cols_timepoint_which_is_top.append(threeM_col)\n",
    "        elif sixW_count > threeM_count and sixW_count > bl_count:\n",
    "            cols_timepoint_which_is_top.append(sixW_col)\n",
    "        else:\n",
    "            cols_timepoint_which_is_top.append(else_col)\n",
    "\n",
    "        if bl_count > threeM_count*4 and bl_count > sixW_count*4:\n",
    "            cols_timepoint_log2_2.append(bl_col)\n",
    "        elif threeM_count > bl_count*4 and threeM_count > sixW_count*4:\n",
    "            cols_timepoint_log2_2.append(threeM_col)\n",
    "        elif sixW_count > threeM_count*4 and sixW_count > bl_count*4:\n",
    "            cols_timepoint_log2_2.append(sixW_col)\n",
    "        else:\n",
    "            cols_timepoint_log2_2.append(else_col)\n",
    "\n",
    "        if bl_count > 0 and threeM_count == 0 and sixW_count == 0:\n",
    "            cols_timepoint_pure.append(bl_col)\n",
    "        elif threeM_count > 0 and bl_count == 0 and sixW_count == 0:\n",
    "            cols_timepoint_pure.append(threeM_col)\n",
    "        elif sixW_count > 0 and threeM_count == 0 and bl_count == 0:\n",
    "            cols_timepoint_pure.append(sixW_col)\n",
    "        else:\n",
    "            cols_timepoint_pure.append(else_col)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cols_individual_points_pure.append(else_col)\n",
    "        cols_individual_points_greater.append(else_col)\n",
    "        cols_individual_points_log2_1.append(else_col)\n",
    "        cols_individual_points_log2_2.append(else_col)\n",
    "        cols_individual_points_log2_3.append(else_col)\n",
    "        cols_timepoint_which_is_top.append(else_col)\n",
    "        cols_timepoint_log2_2.append(else_col)\n",
    "        cols_timepoint_pure.append(else_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa7001",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols_timepoint_which_is_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f22b5-4d1f-4f31-82e1-93dc3f86d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######\n",
    "#FIG 6 A\n",
    "######\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "test = ax.scatter(gliph_embedding_clusters[:, 0],\n",
    "            gliph_embedding_clusters[:, 1],\n",
    "            s=10,\n",
    "            c=cols_individual_points_log2_2)\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "#plt.title(\"UMAP of GLIPH2 convergence groups\", fontsize=30)\n",
    "\n",
    "for i in range(len(hdbscan_cluster_indices_which_pass_test)):\n",
    "    \n",
    "    # Moving the labels slightly\n",
    "    x_offset_for_cluster_label = 0.2\n",
    "    y_offset_for_cluster_label = 0.25\n",
    "    if int(hdbscan_cluster_indices_which_pass_test[i]) > 9:\n",
    "        x_offset_for_cluster_label = 0.4\n",
    "\n",
    "    cluster_index_points = (hdbscan_labels == hdbscan_cluster_indices_which_pass_test[i])\n",
    "    confidence_ellipse(x=gliph_embedding_clusters[cluster_index_points, 0],\n",
    "                       y=gliph_embedding_clusters[cluster_index_points, 1], \n",
    "                       ax=ax, n_std=3.0, edgecolor=\"#666666\", linewidth=2, linestyle=\"-.\")\n",
    "    plt.text(np.mean(gliph_embedding_clusters[cluster_index_points, 0]) - x_offset_for_cluster_label, \n",
    "            np.mean(gliph_embedding_clusters[cluster_index_points, 1]) - y_offset_for_cluster_label, \n",
    "            s=str(hdbscan_cluster_indices_which_pass_test[i]), \n",
    "            fontsize=18)\n",
    "\n",
    "custom_points = [Line2D([], [], marker='.', markersize=20, color='#EE667799', linestyle='None'),\n",
    "                 Line2D([], [], marker='.', markersize=20, color='#4477AA99', linestyle='None'),\n",
    "                 Line2D([], [], marker='.', markersize=20, color='#22883399', linestyle='None'),\n",
    "                 Line2D([], [], marker='.', markersize=20, color='#AAAAAA33', linestyle='None')]\n",
    "\n",
    "custom_lines = [Line2D([], [], color=\"#666666\", lw=2, ls=\"-.\")]\n",
    "\n",
    "legend1 = ax.legend(custom_points, [\"Higher clone count in non-responders\", \n",
    "                                    \"Mixed clone count\", \n",
    "                                    \"Higher clone count in responders\", \n",
    "                                    \"Non-significant clusters\"], \n",
    "                    loc=\"upper right\", \n",
    "                    fontsize=16\n",
    "                    )\n",
    "legend2 = ax.legend(custom_lines, [\"3 SD ellipse for each separate cluster\"], \n",
    "                    loc='lower left', \n",
    "                    bbox_to_anchor=(0.565, 0.73),\n",
    "                    fontsize=16\n",
    "                    )\n",
    "\n",
    "ax.add_artist(legend1)\n",
    "ax.add_artist(legend2)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "plt.xlabel(\"UMAP 1\", fontsize=24)\n",
    "plt.ylabel(\"UMAP 2\", fontsize=24)\n",
    "\n",
    "try:\n",
    "    os.remove(\"blood_UMAP_HDBSCANclusters_ranksumtested_log2_2_withclusterlab.svg\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove(\"blood_UMAP_HDBSCANclusters_ranksumtested_log2_2_withclusterlab.png\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "plt.savefig('blood_UMAP_HDBSCANclusters_ranksumtested_log2_2_withclusterlab.svg')\n",
    "plt.savefig('blood_UMAP_HDBSCANclusters_ranksumtested_log2_2_withclusterlab.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f22b5-4d1f-4f31-82e1-93dc3f86d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######\n",
    "#FIG 6 B\n",
    "######\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "test = ax.scatter(gliph_embedding_clusters[:, 0],\n",
    "            gliph_embedding_clusters[:, 1],\n",
    "            s=10,\n",
    "            c=cols_timepoint_which_is_top)\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "#plt.title(\"UMAP of GLIPH2 convergence groups\", fontsize=30)\n",
    "\n",
    "for i in range(len(hdbscan_cluster_indices_which_pass_test)):\n",
    "    \n",
    "    # Moving the labels slightly\n",
    "    x_offset_for_cluster_label = 0.2\n",
    "    y_offset_for_cluster_label = 0.25\n",
    "    if int(hdbscan_cluster_indices_which_pass_test[i]) > 9:\n",
    "        x_offset_for_cluster_label = 0.4\n",
    "\n",
    "    cluster_index_points = (hdbscan_labels == hdbscan_cluster_indices_which_pass_test[i])\n",
    "    confidence_ellipse(x=gliph_embedding_clusters[cluster_index_points, 0],\n",
    "                       y=gliph_embedding_clusters[cluster_index_points, 1], \n",
    "                       ax=ax, n_std=3.0, edgecolor=\"#666666\", linewidth=2, linestyle=\"-.\")\n",
    "    plt.text(np.mean(gliph_embedding_clusters[cluster_index_points, 0]) - x_offset_for_cluster_label, \n",
    "            np.mean(gliph_embedding_clusters[cluster_index_points, 1]) - y_offset_for_cluster_label, \n",
    "            s=str(hdbscan_cluster_indices_which_pass_test[i]), \n",
    "            fontsize=18)\n",
    "\n",
    "custom_points = [Line2D([], [], marker='.', markersize=20, color='#EE667799', linestyle='None'),\n",
    "                 Line2D([], [], marker='.', markersize=20, color='#4477AA99', linestyle='None'),\n",
    "                 Line2D([], [], marker='.', markersize=20, color='#22883399', linestyle='None'),\n",
    "                 Line2D([], [], marker='.', markersize=20, color='#AAAAAA33', linestyle='None')]\n",
    "\n",
    "custom_lines = [Line2D([], [], color=\"#666666\", lw=2, ls=\"-.\")]\n",
    "\n",
    "legend1 = ax.legend(custom_points, [\"Baseline\",\"6-weeks\", \"12-weeks\",\n",
    "                                    \"Non-significant clusters\"], \n",
    "                    loc=\"upper right\", \n",
    "                    fontsize=16\n",
    "                    )\n",
    "legend2 = ax.legend(custom_lines, [\"3 SD ellipse for each separate cluster\"], \n",
    "                    loc='lower left', \n",
    "                    bbox_to_anchor=(0.565, 0.73),\n",
    "                    fontsize=16\n",
    "                    )\n",
    "\n",
    "ax.add_artist(legend1)\n",
    "ax.add_artist(legend2)\n",
    "\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "plt.xlabel(\"UMAP 1\", fontsize=24)\n",
    "plt.ylabel(\"UMAP 2\", fontsize=24)\n",
    "\n",
    "try:\n",
    "    os.remove(\"blood_UMAP_HDBSCANclusters_ranksumtested_timepoint_top_withclusterlab.svg\")\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(\"blood_UMAP_HDBSCANclusters_ranksumtested_timepoint_top_withclusterlab.png\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "plt.savefig('blood_UMAP_HDBSCANclusters_ranksumtested_timepoint_top_withclusterlab.svg')\n",
    "plt.savefig('blood_UMAP_HDBSCANclusters_ranksumtested_timepoint_top_withclusterlab.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25009d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_indices = dict()\n",
    "\n",
    "for i in hdbscan_cluster_indices_which_pass_test:\n",
    "    #print(i)\n",
    "    cluster_index_patterns = list()\n",
    "    tmp_data = gliph[hdbscan_labels==i]\n",
    "\n",
    "    cluster_indices[i] = tmp_data[\"cluster_index_pattern\"].str.split('_').str[0].values\n",
    "    #print(cluster_indices[i])\n",
    "\n",
    "for i in hdbscan_cluster_indices_which_pass_test:\n",
    "    #print(i)\n",
    "    cluster_index_patterns = list()\n",
    "    tmp_data = gliph[hdbscan_labels==i]\n",
    "\n",
    "    cluster_indices[i] = tmp_data[\"cluster_index_pattern\"].str.split('_').str[0].values\n",
    "    #print(cluster_indices[i])\n",
    "\n",
    "    with open(\"../blood_all_run/blood_all_run_fixedhlatypes_cluster.csv\", \"r\") as gliph_cluster_raw_file, open(\"umap_cluster_\"+str(i)+\"_raw_GLIPH2.csv\", \"w\") as cluster_outfile:\n",
    "        for line in gliph_cluster_raw_file:\n",
    "            if line != \"\\n\":\n",
    "                ll = line.split(\",\")\n",
    "                #print(ll)\n",
    "                cluster_index = ll[0]\n",
    "                if cluster_index in cluster_indices[i]:\n",
    "                    cluster_outfile.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cff9c6-e477-49a0-810f-c003754db263",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(\"blood_index_patterns_significant_responder_clusters.txt\", \"w\")\n",
    "outfile.write(\"cluster_index_pattern\\n\")\n",
    "for i in hdbscan_cluster_indices_which_pass_test:\n",
    "    tmp_count = gliph_data[hdbscan_labels==i]\n",
    "\n",
    "    tmp_count_yes = tmp_count[responders]\n",
    "    tmp_count_no = tmp_count[non_responders]\n",
    "    cluster_values_count_no = np.concatenate(tmp_count_no.to_numpy())\n",
    "    cluster_values_count_yes = np.concatenate(tmp_count_yes.to_numpy())\n",
    "    \n",
    "    tmp_scaled = gliph_data_scaled_df[hdbscan_labels==i]\n",
    "\n",
    "    tmp_scaled_yes = tmp_scaled[responders]\n",
    "    tmp_scaled_no = tmp_scaled[non_responders]\n",
    "    cluster_values_scaled_no = np.concatenate(tmp_scaled_no.to_numpy())\n",
    "    cluster_values_scaled_yes = np.concatenate(tmp_scaled_yes.to_numpy())\n",
    "    \n",
    "    tmp_info_cols = gliph[hdbscan_labels==i]\n",
    "    \n",
    "    if wilcox_results.iloc[i][2]<0:\n",
    "        for l in np.concatenate(np.array(tmp_info_cols[[\"cluster_index_pattern\"]])):\n",
    "            outfile.write(f\"{l}\\n\")\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "167ffdaee51cd8c8100fe98f88937080394971528188a63acfc1cae36451d26f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
